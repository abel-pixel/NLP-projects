{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcWdvALk8AUe",
        "outputId": "bb24df56-a172-460a-d2cd-2766f8018a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyinflect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uspkDv1TfZw",
        "outputId": "1b376e4a-d06e-49c2-e2a8-7112d17fec7c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyinflect in /usr/local/lib/python3.10/dist-packages (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "import pyinflect\n",
        "\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "4PWbR9IPTfen"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# малая модель spacy\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "# малая модель glove wiki\n",
        "# внимание - очень долго скачивает, если она еще не установлена\n",
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "id": "rJSlBkFZTqzw"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# изменение степени прилагательного с помощью pyinflect\n",
        "for token in nlp('Little Red Riding Hood'):\n",
        "    if token.pos_=='ADJ':\n",
        "        print(token.text, token._.inflect('JJS'))\n",
        "        print(token.text, token._.inflect('JJR'))\n",
        "        print(token.text, token._.inflect('JJ'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiWsCcj_Tq5d",
        "outputId": "72472d3b-a6b6-4bb1-8856-d5106a61014f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Little Littlest\n",
            "Little Littler\n",
            "Little Little\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('lived')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUv043IlTfkF",
        "outputId": "a0f201fc-62a8-4e4d-abd0-c89ff0e38fa0"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('living', 0.7721222639083862),\n",
              " ('resided', 0.7559422850608826),\n",
              " ('emigrated', 0.6997494101524353),\n",
              " ('family', 0.6992907524108887),\n",
              " ('lives', 0.6960945129394531),\n",
              " ('died', 0.6883507370948792),\n",
              " ('survived', 0.6847712993621826),\n",
              " ('whom', 0.6718282103538513),\n",
              " ('once', 0.6713927984237671),\n",
              " ('couple', 0.6712842583656311)]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# антонимы – добавляем пару позитив-негатив с противоположными значениями\n",
        "model.most_similar(positive=['lived','bad'], negative=['good'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqMWGIJzVUfr",
        "outputId": "dad7b39f-9eed-4c29-cfc5-9135844644b0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('died', 0.6619753241539001),\n",
              " ('resided', 0.638906717300415),\n",
              " ('fled', 0.6153265833854675),\n",
              " ('emigrated', 0.6144971251487732),\n",
              " ('survived', 0.6038041710853577),\n",
              " ('disappeared', 0.6005083918571472),\n",
              " ('living', 0.590585470199585),\n",
              " ('abandoned', 0.5663079023361206),\n",
              " ('lives', 0.5635175704956055),\n",
              " ('immigrated', 0.5618083477020264)]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтрация стоп слов с помощью спейси\n",
        "word = 'lived'\n",
        "antonyms = model.most_similar(positive=[word,'bad'], negative=['good'])\n",
        "# get words from tuples\n",
        "antonyms = [ _[0] for _ in antonyms]\n",
        "# filter stop words\n",
        "antonyms = [_.text for _ in nlp(' '.join(antonyms)) if not _.is_stop]\n",
        "print('Потенциальные антонимы', word)\n",
        "antonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mB2fsFlVUnE",
        "outputId": "65d630f5-fecf-41a0-9b1b-aad05a475ca1"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Потенциальные антонимы lived\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['died',\n",
              " 'resided',\n",
              " 'fled',\n",
              " 'emigrated',\n",
              " 'survived',\n",
              " 'disappeared',\n",
              " 'living',\n",
              " 'abandoned',\n",
              " 'lives',\n",
              " 'immigrated']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка similarity двух слов с помощью gensim\n",
        "for ant in antonyms:\n",
        "    print(ant, model.similarity('lived', ant))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMVhCxrPVU5o",
        "outputId": "50d684f9-6831-43d0-bd28-33ad9da55e29"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "died 0.68835086\n",
            "resided 0.7559424\n",
            "fled 0.61928064\n",
            "emigrated 0.69974947\n",
            "survived 0.68477136\n",
            "disappeared 0.6009228\n",
            "living 0.77212226\n",
            "abandoned 0.60050607\n",
            "lives 0.6960944\n",
            "immigrated 0.6520551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# как посчитать вручную similarity\n",
        "# можно взять из gensim вектор слова и посчитать косинусное расстояние\n",
        "lived_vec = model['lived']\n",
        "living_vec = model['living']\n",
        "cosine_similarity = (lived_vec @ living_vec)/(np.linalg.norm(lived_vec)*np.linalg.norm(living_vec))\n",
        "cosine_similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INuQfILyVVDb",
        "outputId": "5d91950b-42aa-44fc-dc1d-333794f3b7e7"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.77212226"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('prettiest')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZnEY_QzVVJk",
        "outputId": "3d7b8bdf-5c36-49ca-b782-794e021bf21c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('loveliest', 0.7358776926994324),\n",
              " ('ugliest', 0.7176482677459717),\n",
              " ('sweetest', 0.6964283585548401),\n",
              " ('nicest', 0.6708787083625793),\n",
              " ('cutest', 0.66517174243927),\n",
              " ('weirdest', 0.6551819443702698),\n",
              " ('oddest', 0.6532436609268188),\n",
              " ('strangest', 0.6526945233345032),\n",
              " ('classiest', 0.6503055691719055),\n",
              " ('craziest', 0.6463013291358948)]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# антонимы – добавляем пару позитив-негатив с противоположными значениями\n",
        "model.most_similar(positive=['excessively','bad'], negative=['good'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnAhZHhMWL22",
        "outputId": "b4b0c8ae-237d-407f-96c7-69f7c7a9ce32"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unnecessarily', 0.6572654843330383),\n",
              " ('unduly', 0.6301813721656799),\n",
              " ('appallingly', 0.622342586517334),\n",
              " ('overly', 0.6145561337471008),\n",
              " ('excessive', 0.6109001636505127),\n",
              " ('unconscionably', 0.5999709367752075),\n",
              " ('atrociously', 0.5830274224281311),\n",
              " ('unreasonably', 0.5811731219291687),\n",
              " ('dangerously', 0.5733420848846436),\n",
              " ('burdened', 0.5672959089279175)]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('excessively')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM-fB5iYWL9y",
        "outputId": "719ddf4d-9c1b-4638-9fb9-d2860abfb329"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('overly', 0.7340081930160522),\n",
              " ('unreasonably', 0.6992622017860413),\n",
              " ('unduly', 0.6895744800567627),\n",
              " ('unnecessarily', 0.6870430707931519),\n",
              " ('ridiculously', 0.6779029369354248),\n",
              " ('unconscionably', 0.6673431992530823),\n",
              " ('inordinately', 0.6629543900489807),\n",
              " ('extraordinarily', 0.65824955701828),\n",
              " ('absurdly', 0.6548056602478027),\n",
              " ('appallingly', 0.653618335723877)]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('woman')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CbnjSIOxMTv",
        "outputId": "4c38f13c-ab0d-4e0d-e69d-810c4bab41ad"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('girl', 0.8472671508789062),\n",
              " ('man', 0.832349419593811),\n",
              " ('mother', 0.827568769454956),\n",
              " ('boy', 0.7720510363578796),\n",
              " ('she', 0.7632068395614624),\n",
              " ('child', 0.7601762413978577),\n",
              " ('wife', 0.7505022883415222),\n",
              " ('her', 0.7445706129074097),\n",
              " ('herself', 0.7426273822784424),\n",
              " ('daughter', 0.726445734500885)]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for token in nlp('It suited the girl so extremely well that everybody called her Little Red Riding Hood'):\n",
        "    if token.pos_=='VERB':\n",
        "        print(token.text, token._.inflect('VB'))\n",
        "        print(token.text, token._.inflect('VBZ'))\n",
        "        print(token.text, token._.inflect('VBD'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-6XZfFkZJle",
        "outputId": "94e8d780-6817-4bfe-ffc8-8c261015179e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "suited suit\n",
            "suited suits\n",
            "suited suited\n",
            "called call\n",
            "called calls\n",
            "called called\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for token in nlp('One day her mother, having made some cakes, said to her, \"Go, my dear, and see how your grandmother is doing, for I hear she has been very ill.'):\n",
        "    if token.pos_=='NOUN':\n",
        "        print(token.text, token._.inflect('NN'))\n",
        "        print(token.text, token._.inflect('NNS'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avO2_pVKZJuM",
        "outputId": "d9be4563-97aa-450f-ec9d-9b4af509b0e8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day day\n",
            "day days\n",
            "mother mother\n",
            "mother mothers\n",
            "cakes cake\n",
            "cakes cakes\n",
            "dear dear\n",
            "dear dears\n",
            "grandmother grandmother\n",
            "grandmother grandmothers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# на случайные близкие слова и анти-слова\n",
        "sent = 'Take her a cake, and this little pot of butter.'\n",
        "new_sent_1, new_sent_2 = sent, sent\n",
        "i=5\n",
        "for token in nlp(sent):\n",
        "    if token.pos_ in ['VERB']:\n",
        "        m, n = np.random.randint(0, i, 2)\n",
        "\n",
        "        new_word_1 = model.most_similar(token.text.lower(), topn=i)[m][0]\n",
        "        new_word_2 = model.most_similar(positive = [token.text.lower(), 'bad'],\n",
        "                                        negative = ['good'],\n",
        "                                        topn=i)[n][0]\n",
        "\n",
        "        new_word_1 = new_word_1.title() if token.text.istitle() else new_word_1\n",
        "        new_word_2 = new_word_2.title() if token.text.istitle() else new_word_2\n",
        "\n",
        "        new_sent_1 = new_sent_1.replace(token.text, new_word_1)\n",
        "        new_sent_2 = new_sent_2.replace(token.text, new_word_2)\n",
        "\n",
        "print(sent)\n",
        "print(new_sent_1)\n",
        "print(new_sent_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiICCx6PcEu0",
        "outputId": "760010a5-24b3-43bb-a2e1-d371a2ed54da"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Take her a cake, and this little pot of butter.\n",
            "Give her a cake, and this little pot of butter.\n",
            "Go her a cake, and this little pot of butter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтрация стоп слов с помощью спейси\n",
        "word = 'butter'\n",
        "antonyms = model.most_similar(positive=[word,'bad'], negative=['good'])\n",
        "# get words from tuples\n",
        "antonyms = [ _[0] for _ in antonyms]\n",
        "# filter stop words\n",
        "antonyms = [_.text for _ in nlp(' '.join(antonyms)) if not _.is_stop]\n",
        "print('Потенциальные антонимы', word)\n",
        "antonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhdUVXVHcFXX",
        "outputId": "3def0ec5-656c-4527-eb0b-8abdc433e73e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Потенциальные антонимы butter\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['margarine',\n",
              " 'melted',\n",
              " 'melt',\n",
              " 'cheese',\n",
              " 'flour',\n",
              " 'peanut',\n",
              " 'syrup',\n",
              " 'chopped',\n",
              " 'sour',\n",
              " 'stir']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка similarity двух слов с помощью gensim\n",
        "for ant in antonyms:\n",
        "    print(ant, model.similarity('butter', ant))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COyGg6P3cFg6",
        "outputId": "375c6545-7580-46ab-ee66-36533cd7cdc2"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "margarine 0.8079419\n",
            "melted 0.7524646\n",
            "melt 0.6629708\n",
            "cheese 0.77912\n",
            "flour 0.75192404\n",
            "peanut 0.7813067\n",
            "syrup 0.7206409\n",
            "chopped 0.6637064\n",
            "sour 0.58706975\n",
            "stir 0.7044655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтрация стоп слов с помощью спейси\n",
        "word = 'immediately'\n",
        "antonyms = model.most_similar(positive=[word,'bad'], negative=['good'])\n",
        "# get words from tuples\n",
        "antonyms = [ _[0] for _ in antonyms]\n",
        "# filter stop words\n",
        "antonyms = [_.text for _ in nlp(' '.join(antonyms)) if not _.is_stop]\n",
        "print('Потенциальные антонимы', word)\n",
        "antonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxGyjO9seFnz",
        "outputId": "8cd59dc6-9908-4b5f-cd68-5c0e0e0aefc6"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Потенциальные антонимы immediately\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['forced',\n",
              " 'soon',\n",
              " 'shortly',\n",
              " 'caused',\n",
              " 'promptly',\n",
              " 'temporarily',\n",
              " 'quickly',\n",
              " 'avoid',\n",
              " 'incident',\n",
              " 'apparently']"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка similarity двух слов с помощью gensim\n",
        "for ant in antonyms:\n",
        "    print(ant, model.similarity('immediately', ant))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsEI_CnMeMgW",
        "outputId": "1e10a755-b462-4f22-d7a5-37b995b67c97"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forced 0.6699287\n",
            "soon 0.8437643\n",
            "shortly 0.7703622\n",
            "caused 0.55561686\n",
            "promptly 0.77182955\n",
            "temporarily 0.6881569\n",
            "quickly 0.8234099\n",
            "avoid 0.6605484\n",
            "incident 0.64048964\n",
            "apparently 0.7204884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('As she was going through the wood, she met with a wolf, who had a very great mind to eat her up, but he dared not, because of some woodcutters working nearby in the forest.'):\n",
        "    if token.pos_=='NOUN':\n",
        "        print(token.text, token._.inflect('NN'))\n",
        "        print(token.text, token._.inflect('NNS'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mneDd6NgeMmX",
        "outputId": "d4e9dc91-a3a8-4833-fb75-bfade4a05820"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wood wood\n",
            "wood woods\n",
            "wolf wolf\n",
            "wolf wolves\n",
            "mind mind\n",
            "mind minds\n",
            "woodcutters woodcutter\n",
            "woodcutters woodcutters\n",
            "forest forest\n",
            "forest forests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('As she was going through the wood, she met with a wolf, who had a very great mind to eat her up, but he dared not, because of some woodcutters working nearby in the forest.'):\n",
        "    if token.pos_=='VERB':\n",
        "        print(token.text, token._.inflect('VB'))\n",
        "        print(token.text, token._.inflect('VBZ'))\n",
        "        print(token.text, token._.inflect('VBD'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgoSQwscfOWL",
        "outputId": "1be6f721-7d7b-47a1-a5a5-b49a0f00267a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "going go\n",
            "going goes\n",
            "going went\n",
            "met meet\n",
            "met meets\n",
            "met met\n",
            "had have\n",
            "had has\n",
            "had had\n",
            "eat eat\n",
            "eat eats\n",
            "eat ate\n",
            "dared dare\n",
            "dared dares\n",
            "dared dared\n",
            "working work\n",
            "working works\n",
            "working wrought\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('As she was going through the wood, she met with a wolf, who had a very great mind to eat her up, but he dared not, because of some woodcutters working nearby in the forest.'):\n",
        "    if token.pos_=='ADJ':\n",
        "        print(token.text, token._.inflect('JJS'))\n",
        "        print(token.text, token._.inflect('JJR'))\n",
        "        print(token.text, token._.inflect('JJ'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDXKmCiVfOea",
        "outputId": "9cc1b5af-9112-4618-b908-deb38d980f28"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "great greatest\n",
            "great greater\n",
            "great great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('He asked her where she was going'):\n",
        "    if token.pos_=='VERB':\n",
        "        print(token.text, token._.inflect('VB'))\n",
        "        print(token.text, token._.inflect('VBZ'))\n",
        "        print(token.text, token._.inflect('VBD'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p8Ucbhwfzu7",
        "outputId": "497e06bb-a95d-4cdf-df0b-c290d4d8977c"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asked ask\n",
            "asked asks\n",
            "asked asked\n",
            "going go\n",
            "going goes\n",
            "going went\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('dangerous')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnnQEqqjf0At",
        "outputId": "78158e5b-bcb2-45f1-b253-cf5b903159d4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('difficult', 0.7275011539459229),\n",
              " ('potentially', 0.7120583653450012),\n",
              " ('serious', 0.6858029365539551),\n",
              " ('destructive', 0.6796632409095764),\n",
              " ('danger', 0.6740216612815857),\n",
              " ('unpredictable', 0.6732596158981323),\n",
              " ('violent', 0.6720824837684631),\n",
              " ('deadly', 0.6691234111785889),\n",
              " ('extremely', 0.6673955917358398),\n",
              " ('vulnerable', 0.6656883955001831)]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтрация стоп слов с помощью спейси\n",
        "word = 'carry'\n",
        "antonyms = model.most_similar(positive=[word,'bad'], negative=['good'])\n",
        "# get words from tuples\n",
        "antonyms = [ _[0] for _ in antonyms]\n",
        "# filter stop words\n",
        "antonyms = [_.text for _ in nlp(' '.join(antonyms)) if not _.is_stop]\n",
        "print('Потенциальные антонимы', word)\n",
        "antonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9f_CR8bf0Mg",
        "outputId": "09d73487-e6f8-488e-c95e-5d532e104f2b"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Потенциальные антонимы carry\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['carried',\n",
              " 'carrying',\n",
              " 'avoid',\n",
              " 'stop',\n",
              " 'causing',\n",
              " 'prevent',\n",
              " 'handle',\n",
              " 'caused',\n",
              " 'massive',\n",
              " 'forced']"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка similarity двух слов с помощью gensim\n",
        "for ant in antonyms:\n",
        "    print(ant, model.similarity('carry', ant))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mOlSJaMf0T9",
        "outputId": "d9b8103d-6984-4709-be1f-a79d2beb89df"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "carried 0.77079064\n",
            "carrying 0.7303496\n",
            "avoid 0.5921266\n",
            "stop 0.6480684\n",
            "causing 0.45596516\n",
            "prevent 0.61330664\n",
            "handle 0.6858238\n",
            "caused 0.42871833\n",
            "massive 0.53908134\n",
            "forced 0.5081295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('\"Does she live far off?\" said the wolf'):\n",
        "    if token.pos_=='VERB':\n",
        "        print(token.text, token._.inflect('VB'))\n",
        "        print(token.text, token._.inflect('VBZ'))\n",
        "        print(token.text, token._.inflect('VBD'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW9qNS1djggh",
        "outputId": "27deb418-0ceb-497c-b1f8-2961cee1fb44"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "live live\n",
            "live lives\n",
            "live lived\n",
            "said say\n",
            "said says\n",
            "said said\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('\"Oh I say,\" answered Little Red Riding Hood; \"it is beyond that mill you see there, at the first house in the village.\"'):\n",
        "    if token.pos_=='ADJ':\n",
        "        print(token.text, token._.inflect('JJS'))\n",
        "        print(token.text, token._.inflect('JJR'))\n",
        "        print(token.text, token._.inflect('JJ'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn0Ruoy3jgoy",
        "outputId": "e889f59b-2925-4713-877b-027b04549fe2"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first firstest\n",
            "first firster\n",
            "first first\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтрация стоп слов с помощью спейси\n",
        "word = 'way'\n",
        "antonyms = model.most_similar(positive=[word,'bad'], negative=['good'])\n",
        "# get words from tuples\n",
        "antonyms = [ _[0] for _ in antonyms]\n",
        "# filter stop words\n",
        "antonyms = [_.text for _ in nlp(' '.join(antonyms)) if not _.is_stop]\n",
        "print('Потенциальные антонимы', word)\n",
        "antonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3DftpQWlUkz",
        "outputId": "dd85f07d-cfd6-4239-9326-c1afb20c42aa"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Потенциальные антонимы way\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['turn', 'going', 'wrong', 'things']"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка similarity двух слов с помощью gensim\n",
        "for ant in antonyms:\n",
        "    print(ant, model.similarity('way', ant))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N39GJJF4lUtG",
        "outputId": "4462d3c4-d317-4fbd-b368-993e830ec458"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "turn 0.82955754\n",
            "going 0.8569827\n",
            "wrong 0.71910506\n",
            "things 0.8247758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('there')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz6Naja6lU1O",
        "outputId": "348d2fbc-d567-44ec-c974-078f3dcb215f"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('no', 0.8889176249504089),\n",
              " ('only', 0.8587634563446045),\n",
              " ('some', 0.8572323322296143),\n",
              " ('but', 0.854871928691864),\n",
              " ('so', 0.8500323295593262),\n",
              " ('this', 0.8480582237243652),\n",
              " ('they', 0.8431913256645203),\n",
              " ('though', 0.8426817655563354),\n",
              " ('now', 0.8422872424125671),\n",
              " ('what', 0.8381678462028503)]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('path')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaBuo1Wqqg1j",
        "outputId": "298a668d-d4a8-41d8-b033-f1f34e5076b8"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('paths', 0.7559518814086914),\n",
              " ('toward', 0.6760907173156738),\n",
              " ('direction', 0.6682589650154114),\n",
              " ('way', 0.6522889137268066),\n",
              " ('road', 0.6374226212501526),\n",
              " ('towards', 0.634418249130249),\n",
              " ('clear', 0.633200466632843),\n",
              " ('journey', 0.6222858428955078),\n",
              " ('approach', 0.6212446093559265),\n",
              " ('trail', 0.6101217269897461)]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('roundabout')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sol3wr1oq5FJ",
        "outputId": "a88829c9-4268-4e74-c1fa-5d4c7bae7e80"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('thoroughfare', 0.613814115524292),\n",
              " ('intersection', 0.6035764813423157),\n",
              " ('boulevard', 0.5774850845336914),\n",
              " ('broadway', 0.5733689665794373),\n",
              " ('junction', 0.5629505515098572),\n",
              " ('esplanade', 0.5551373958587646),\n",
              " ('gate', 0.546811044216156),\n",
              " ('terminates', 0.5445003509521484),\n",
              " ('avenue', 0.5416954159736633),\n",
              " ('crossroads', 0.5413249135017395)]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтрация стоп слов с помощью спейси\n",
        "word = 'roundabout'\n",
        "antonyms = model.most_similar(positive=[word,'bad'], negative=['good'])\n",
        "# get words from tuples\n",
        "antonyms = [ _[0] for _ in antonyms]\n",
        "# filter stop words\n",
        "antonyms = [_.text for _ in nlp(' '.join(antonyms)) if not _.is_stop]\n",
        "print('Потенциальные антонимы', word)\n",
        "antonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KWcdDBjq5Nz",
        "outputId": "899a04c8-c3c1-4a20-82fd-24dec939263f"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Потенциальные антонимы roundabout\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['intersection',\n",
              " 'hairpin',\n",
              " 'thoroughfare',\n",
              " 'intersecting',\n",
              " '-',\n",
              " 'pass',\n",
              " 'terminates',\n",
              " 'freeway',\n",
              " 'broadway',\n",
              " 'i-5',\n",
              " 'expressway']"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка similarity двух слов с помощью gensim\n",
        "for ant in antonyms:\n",
        "    print(ant, model.similarity('roundabout', ant))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewe5LVbTq5Ua",
        "outputId": "dee5ba3f-e32d-4bb4-9c19-eb82bfa6f97d"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intersection 0.6035765\n",
            "hairpin 0.5092227\n",
            "thoroughfare 0.61381406\n",
            "intersecting 0.49770108\n",
            "- 0.014921978\n",
            "pass 0.14181137\n",
            "terminates 0.54450023\n",
            "freeway 0.4979262\n",
            "broadway 0.57336897\n",
            "i-5 0.4723395\n",
            "expressway 0.47346207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('butterflies')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smy2Ct5zrPtX",
        "outputId": "4a91caa3-150f-4976-93ac-02dd3cf9524a"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('moths', 0.7957603931427002),\n",
              " ('insects', 0.7567256689071655),\n",
              " ('dragonflies', 0.7413623332977295),\n",
              " ('orchids', 0.7138190865516663),\n",
              " ('caterpillars', 0.6863438487052917),\n",
              " ('beetles', 0.6748114228248596),\n",
              " ('birds', 0.6679182648658752),\n",
              " ('bees', 0.6228375434875488),\n",
              " ('flies', 0.6177154779434204),\n",
              " ('hummingbirds', 0.6128782629966736)]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('house')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j20pXpSkrP1C",
        "outputId": "50e680c6-c973-4542-89f1-628b2286df4b"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('office', 0.7581615447998047),\n",
              " ('senate', 0.7204986810684204),\n",
              " ('room', 0.7149738669395447),\n",
              " ('houses', 0.6888046264648438),\n",
              " ('capitol', 0.6851760149002075),\n",
              " ('building', 0.684728741645813),\n",
              " ('home', 0.672031044960022),\n",
              " ('clinton', 0.6707026958465576),\n",
              " ('congressional', 0.669257640838623),\n",
              " ('mansion', 0.665092408657074)]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('He knocked at the door: tap, tap.'):\n",
        "    if token.pos_=='VERB':\n",
        "        print(token.text, token._.inflect('VB'))\n",
        "        print(token.text, token._.inflect('VBZ'))\n",
        "        print(token.text, token._.inflect('VBD'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMkuFO7vsxIw",
        "outputId": "5e57f4ea-7c8c-4a00-e2e0-5a0ca80e1731"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knocked knock\n",
            "knocked knockes\n",
            "knocked knocked\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('there')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9_2P7qmsxS8",
        "outputId": "5364f922-2967-4b9d-e594-384a9f285e0e"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('no', 0.8889176249504089),\n",
              " ('only', 0.8587634563446045),\n",
              " ('some', 0.8572323322296143),\n",
              " ('but', 0.854871928691864),\n",
              " ('so', 0.8500323295593262),\n",
              " ('this', 0.8480582237243652),\n",
              " ('they', 0.8431913256645203),\n",
              " ('though', 0.8426817655563354),\n",
              " ('now', 0.8422872424125671),\n",
              " ('what', 0.8381678462028503)]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('counterfeiting')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEbiC9cvsxY8",
        "outputId": "f8eb9a9b-11ef-4fae-cec2-6a13b3109a16"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('laundering', 0.7594428062438965),\n",
              " ('counterfeit', 0.6539453864097595),\n",
              " ('piracy', 0.6462855339050293),\n",
              " ('smuggling', 0.617916464805603),\n",
              " ('trafficking', 0.6048997044563293),\n",
              " ('forgery', 0.6027125120162964),\n",
              " ('peddling', 0.5857939124107361),\n",
              " ('illicit', 0.5817586779594421),\n",
              " ('evasion', 0.5638552308082581),\n",
              " ('extortion', 0.5566224455833435)]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('butter')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPSO-rKHuMdr",
        "outputId": "e5694f64-3880-4555-8c8c-0507285c4b82"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('margarine', 0.8079419136047363),\n",
              " ('cream', 0.7990189790725708),\n",
              " ('peanut', 0.7813066840171814),\n",
              " ('cheese', 0.7791200876235962),\n",
              " ('chocolate', 0.7580447196960449),\n",
              " ('melted', 0.7524645328521729),\n",
              " ('flour', 0.7519240379333496),\n",
              " ('sauce', 0.7376376986503601),\n",
              " ('vanilla', 0.7348540425300598),\n",
              " ('baking', 0.7293545603752136)]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# антонимы – добавляем пару позитив-негатив с противоположными значениями\n",
        "model.most_similar(positive=['good','bad'], negative=['good'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGH0tjgDuMzf",
        "outputId": "93b314a3-a6f3-4ada-ff84-8afb50b14b6d"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('worse', 0.7929712533950806),\n",
              " ('things', 0.7653602957725525),\n",
              " ('too', 0.7630148530006409),\n",
              " ('thing', 0.7609667778015137),\n",
              " ('lot', 0.7443646788597107),\n",
              " ('kind', 0.7408681511878967),\n",
              " ('because', 0.739879846572876),\n",
              " ('really', 0.7376540899276733),\n",
              " (\"n't\", 0.7336540818214417),\n",
              " ('little', 0.7281355857849121)]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('good')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY-BYvl7uM5z",
        "outputId": "09aa74b9-2ec9-4f9a-fbb0-9366199f6250"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('better', 0.893191397190094),\n",
              " ('sure', 0.8314563035964966),\n",
              " ('really', 0.8297762274742126),\n",
              " ('kind', 0.8288268446922302),\n",
              " ('very', 0.8260800242424011),\n",
              " ('we', 0.8234355449676514),\n",
              " ('way', 0.8215398192405701),\n",
              " ('think', 0.8205099105834961),\n",
              " ('thing', 0.8171301484107971),\n",
              " (\"'re\", 0.8141680955886841)]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('bobbin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYI4ubxJwUiv",
        "outputId": "22139698-1dbe-4e48-f349-fe3145ae5b11"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('moire', 0.5209357738494873),\n",
              " ('doody', 0.5124744176864624),\n",
              " ('lace', 0.5009957551956177),\n",
              " ('belling', 0.4997113049030304),\n",
              " ('weft', 0.4916817843914032),\n",
              " ('rollin', 0.48743078112602234),\n",
              " ('poochie', 0.4815025329589844),\n",
              " ('bobbins', 0.4781877398490906),\n",
              " ('bramo', 0.4764481782913208),\n",
              " ('floss', 0.4735659062862396)]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('pulled')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iL6d_8S8Bhy",
        "outputId": "7d6078c2-573f-4fa6-fae2-60d71c573834"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pulling', 0.7936134934425354),\n",
              " ('off', 0.7768003344535828),\n",
              " ('back', 0.7689379453659058),\n",
              " ('picked', 0.7561824321746826),\n",
              " ('pull', 0.7560582160949707),\n",
              " ('away', 0.7401852011680603),\n",
              " ('pushed', 0.7299758195877075),\n",
              " ('knocked', 0.7287973761558533),\n",
              " ('grabbed', 0.7275064587593079),\n",
              " ('rolled', 0.7274501323699951)]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('moment')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJyD4A808BsU",
        "outputId": "6857c93c-4b7b-4b90-ddf0-ffa76dca856b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('moments', 0.8475146889686584),\n",
              " ('thing', 0.8067348599433899),\n",
              " ('mind', 0.7597180008888245),\n",
              " ('sort', 0.7511561512947083),\n",
              " ('kind', 0.7459704875946045),\n",
              " ('something', 0.7444869875907898),\n",
              " ('happened', 0.7356367707252502),\n",
              " ('remember', 0.7342726588249207),\n",
              " ('what', 0.7298220992088318),\n",
              " ('happens', 0.7289209961891174)]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('door')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9DA0klQ9xuZ",
        "outputId": "35d82ebc-2861-49ac-9da0-2329100b667d"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('doors', 0.8562019467353821),\n",
              " ('window', 0.8181455135345459),\n",
              " ('room', 0.7539054751396179),\n",
              " ('inside', 0.7108698487281799),\n",
              " ('floor', 0.7052059769630432),\n",
              " ('sitting', 0.6876002550125122),\n",
              " ('front', 0.680144727230072),\n",
              " ('waiting', 0.6790406703948975),\n",
              " ('hand', 0.6632920503616333),\n",
              " ('locked', 0.6594761610031128)]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('expecting')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhDPCSHA9x4G",
        "outputId": "03058c27-774b-4139-a630-14ca26b55ead"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('expect', 0.8273691534996033),\n",
              " ('anticipating', 0.7498417496681213),\n",
              " ('expectations', 0.7260172367095947),\n",
              " ('expects', 0.7201017141342163),\n",
              " ('optimistic', 0.7089706659317017),\n",
              " ('anticipate', 0.6928597688674927),\n",
              " ('predicting', 0.6916440725326538),\n",
              " ('seeing', 0.6915954947471619),\n",
              " ('anticipated', 0.682197093963623),\n",
              " ('surprised', 0.6792380809783936)]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('hearing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq07hg-a_3NJ",
        "outputId": "bfde985a-479c-4e6e-9ee9-1952d1b04a23"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hearings', 0.7677700519561768),\n",
              " ('court', 0.7499337196350098),\n",
              " ('proceedings', 0.7430045008659363),\n",
              " ('jury', 0.7308874726295471),\n",
              " ('testimony', 0.7229984402656555),\n",
              " ('trial', 0.722489058971405),\n",
              " ('hear', 0.7202497720718384),\n",
              " ('judge', 0.7131830453872681),\n",
              " ('case', 0.7046642899513245),\n",
              " ('heard', 0.6963950395584106)]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# фильтрация стоп слов с помощью спейси\n",
        "word = 'believing'\n",
        "antonyms = model.most_similar(positive=[word,'bad'], negative=['good'])\n",
        "# get words from tuples\n",
        "antonyms = [ _[0] for _ in antonyms]\n",
        "# filter stop words\n",
        "antonyms = [_.text for _ in nlp(' '.join(antonyms)) if not _.is_stop]\n",
        "print('Потенциальные антонимы', word)\n",
        "antonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ7DOWwv_3Uo",
        "outputId": "3a1d6fcb-1a6e-47ed-e849-4e9a38e79014"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Потенциальные антонимы believing\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blaming',\n",
              " 'blame',\n",
              " 'afraid',\n",
              " 'scared',\n",
              " 'unaware',\n",
              " 'fear',\n",
              " 'fearful',\n",
              " 'knowing',\n",
              " 'worried',\n",
              " 'suspecting']"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка similarity двух слов с помощью gensim\n",
        "for ant in antonyms:\n",
        "    print(ant, model.similarity('believing', ant))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBgpgnyfAlCZ",
        "outputId": "177cb7a1-1645-4db8-e7db-a2b5f179c5b5"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blaming 0.515885\n",
            "blame 0.5642224\n",
            "afraid 0.6741363\n",
            "scared 0.5688521\n",
            "unaware 0.6319026\n",
            "fear 0.61684257\n",
            "fearful 0.5719971\n",
            "knowing 0.75471795\n",
            "worried 0.62038374\n",
            "suspecting 0.58531433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('grandchild')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcyVWDRJAlP1",
        "outputId": "9fa5e548-69f0-4764-93a6-3938e8edee8c"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('granddaughter', 0.6973433494567871),\n",
              " ('grandparent', 0.6881345510482788),\n",
              " ('grandchildren', 0.688111424446106),\n",
              " ('niece', 0.679613471031189),\n",
              " ('granddaughters', 0.6711245179176331),\n",
              " ('grandparents', 0.6521943807601929),\n",
              " ('nieces', 0.6283237934112549),\n",
              " ('grandsons', 0.6256321668624878),\n",
              " ('firstborn', 0.6148455142974854),\n",
              " ('great-grandchild', 0.6085379719734192)]"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('softening')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzXrqEE9Alac",
        "outputId": "57ac7fe0-a854-42ce-d018-e8b2c6b0ba1a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('weakening', 0.7141451835632324),\n",
              " ('hardening', 0.7134581208229065),\n",
              " ('easing', 0.6805393099784851),\n",
              " ('moderating', 0.6737066507339478),\n",
              " ('firming', 0.6558446884155273),\n",
              " ('soften', 0.6458730101585388),\n",
              " ('slowing', 0.638678789138794),\n",
              " ('softness', 0.6294131875038147),\n",
              " ('slowdown', 0.6200348138809204),\n",
              " ('dampening', 0.6113205552101135)]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('latch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlzmlOEEAljT",
        "outputId": "429193f9-3a03-4ba1-eb49-4fba3703e2d4"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('latches', 0.7570903301239014),\n",
              " ('locking', 0.5653749704360962),\n",
              " ('latching', 0.5628824830055237),\n",
              " ('deadbolt', 0.5432531833648682),\n",
              " ('handrails', 0.540752649307251),\n",
              " ('choke', 0.536155641078949),\n",
              " ('throttle', 0.5289207100868225),\n",
              " ('vibrate', 0.5224570631980896),\n",
              " ('fasten', 0.5202547907829285),\n",
              " ('latched', 0.5198674201965332)]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# на случайные близкие слова и анти-слова\n",
        "noun = \"Little Red Riding Hood pulled the bobbin, and the door opened.\"\n",
        "new_noun_1, new_noun_2 = noun, noun\n",
        "i=5\n",
        "for token in nlp(noun):\n",
        "    if token.pos_ in ['NOUN', 'VERB', 'ADV', 'ADJ']:\n",
        "        m, n = np.random.randint(0, i, 2)\n",
        "\n",
        "        new_word_1 = model.most_similar(token.text.lower(), topn=i)[m][0]\n",
        "        new_word_2 = model.most_similar(positive = [token.text.lower(), 'bad'],\n",
        "                                        negative = ['good'],\n",
        "                                        topn=i)[n][0]\n",
        "\n",
        "        new_word_1 = new_word_1.title() if token.text.istitle() else new_word_1\n",
        "        new_word_2 = new_word_2.title() if token.text.istitle() else new_word_2\n",
        "\n",
        "        new_noun_1 = new_noun_1.replace(token.text, new_word_1)\n",
        "        new_noun_2 = new_noun_2.replace(token.text, new_word_2)\n",
        "\n",
        "print(noun)\n",
        "print(new_noun_1)\n",
        "print(new_noun_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YFzKsK6hZiT",
        "outputId": "8379027e-bf8b-496c-f6ca-b7eb6302423b"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Little Red Riding Hood pulled the bobbin, and the door opened.\n",
            "Too Red Riding Hood back the weft, and the window closed.\n",
            "Bit Red Riding Hood pull the bramo, and the locked closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('Little Red Riding Hood pulled the bobbin, and the door opened.'):\n",
        "    if token.pos_=='VERB':\n",
        "        print(token.text, token._.inflect('VB'))\n",
        "        print(token.text, token._.inflect('VBZ'))\n",
        "        print(token.text, token._.inflect('VBD'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkZ5W7vlDMSP",
        "outputId": "73eda802-5803-4c7d-da69-ea28ce352a8c"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pulled pull\n",
            "pulled pulls\n",
            "pulled pulled\n",
            "opened open\n",
            "opened opens\n",
            "opened opened\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('seeing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENsdaXrcDMb1",
        "outputId": "67721c56-3a61-4916-eba8-c1b6e7215c1d"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('looking', 0.8002535104751587),\n",
              " ('watching', 0.7961147427558899),\n",
              " ('saw', 0.7877046465873718),\n",
              " ('everyone', 0.7772706747055054),\n",
              " ('see', 0.7740123271942139),\n",
              " (\"'re\", 0.7711707949638367),\n",
              " ('talking', 0.7640077471733093),\n",
              " ('getting', 0.7607728242874146),\n",
              " ('seen', 0.7606708407402039),\n",
              " ('why', 0.7542959451675415)]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('bedclothes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeAjp9dkE1uP",
        "outputId": "46900d7e-1533-4877-8c32-21e10252c451"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bedcovers', 0.664415180683136),\n",
              " ('bedrolls', 0.6588523387908936),\n",
              " ('schoolbags', 0.6473395228385925),\n",
              " ('inkwells', 0.6444849371910095),\n",
              " ('nightclothes', 0.6198785901069641),\n",
              " ('woollens', 0.614671528339386),\n",
              " ('bunkmates', 0.6104326248168945),\n",
              " ('luggages', 0.6023505330085754),\n",
              " ('barcalounger', 0.600226879119873),\n",
              " ('sideboards', 0.5999171137809753)]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# на случайные близкие слова и анти-слова\n",
        "noun = \"Little Red Riding Hood took off her clothes and got into bed.\"\n",
        "new_noun_1, new_noun_2 = noun, noun\n",
        "i=5\n",
        "for token in nlp(noun):\n",
        "    if token.pos_ in ['NOUN', 'VERB', 'ADV', 'ADJ']:\n",
        "        m, n = np.random.randint(0, i, 2)\n",
        "\n",
        "        new_word_1 = model.most_similar(token.text.lower(), topn=i)[m][0]\n",
        "        new_word_2 = model.most_similar(positive = [token.text.lower(), 'bad'],\n",
        "                                        negative = ['good'],\n",
        "                                        topn=i)[n][0]\n",
        "\n",
        "        new_word_1 = new_word_1.title() if token.text.istitle() else new_word_1\n",
        "        new_word_2 = new_word_2.title() if token.text.istitle() else new_word_2\n",
        "\n",
        "        new_noun_1 = new_noun_1.replace(token.text, new_word_1)\n",
        "        new_noun_2 = new_noun_2.replace(token.text, new_word_2)\n",
        "\n",
        "print(noun)\n",
        "print(new_noun_1)\n",
        "print(new_noun_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26rNM7qvgUFl",
        "outputId": "af4474f6-53b9-472f-d2b6-d507efef211f"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Little Red Riding Hood took off her clothes and got into bed.\n",
            "Just Red Riding Hood came off her shoes and 've into mattress.\n",
            "Too Red Riding Hood followed off her shoes and getting into asleep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('bed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVoSnrFrFemD",
        "outputId": "bc31f129-e1bf-477e-d0bf-505257a49e39"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('beds', 0.7630816102027893),\n",
              " ('sleeping', 0.7616755366325378),\n",
              " ('room', 0.7250885963439941),\n",
              " ('bedroom', 0.6915375590324402),\n",
              " ('mattress', 0.6799733638763428),\n",
              " ('sitting', 0.670059084892273),\n",
              " ('bathroom', 0.6695295572280884),\n",
              " ('sleep', 0.6524335741996765),\n",
              " ('couch', 0.6479793787002563),\n",
              " ('slept', 0.6461016535758972)]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('amazed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFImHK6gFexm",
        "outputId": "52edb136-9c0b-44db-ef24-4974b618a2ee"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('astonished', 0.9051270484924316),\n",
              " ('astounded', 0.8492513298988342),\n",
              " ('thrilled', 0.8213180303573608),\n",
              " ('appalled', 0.7945465445518494),\n",
              " ('delighted', 0.7768217921257019),\n",
              " ('awed', 0.7736601829528809),\n",
              " ('horrified', 0.7710898518562317),\n",
              " ('intrigued', 0.7709209322929382),\n",
              " ('mystified', 0.7645464539527893),\n",
              " ('elated', 0.7514320611953735)]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('arms')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csA85igiFe5f",
        "outputId": "b7ef0536-77dd-447c-93c6-058395da6248"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('weapons', 0.7807133197784424),\n",
              " ('hands', 0.6645297408103943),\n",
              " ('hand', 0.6610875725746155),\n",
              " ('weapon', 0.624072790145874),\n",
              " ('armed', 0.6143966317176819),\n",
              " ('arm', 0.6058312058448792),\n",
              " ('holding', 0.6043851971626282),\n",
              " ('guns', 0.6008465886116028),\n",
              " ('iraq', 0.5929712057113647),\n",
              " ('u.n.', 0.5912413597106934)]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# на случайные близкие слова и анти-слова\n",
        "noun = \"All the better to hug you with, my dear.\"\n",
        "new_noun_1, new_noun_2 = noun, noun\n",
        "i=5\n",
        "for token in nlp(noun):\n",
        "    if token.pos_ in ['NOUN', 'VERB', 'ADV', 'ADJ']:\n",
        "        m, n = np.random.randint(0, i, 2)\n",
        "\n",
        "        new_word_1 = model.most_similar(token.text.lower(), topn=i)[m][0]\n",
        "        new_word_2 = model.most_similar(positive = [token.text.lower(), 'bad'],\n",
        "                                        negative = ['good'],\n",
        "                                        topn=i)[n][0]\n",
        "\n",
        "        new_word_1 = new_word_1.title() if token.text.istitle() else new_word_1\n",
        "        new_word_2 = new_word_2.title() if token.text.istitle() else new_word_2\n",
        "\n",
        "        new_noun_1 = new_noun_1.replace(token.text, new_word_1)\n",
        "        new_noun_2 = new_noun_2.replace(token.text, new_word_2)\n",
        "\n",
        "print(noun)\n",
        "print(new_noun_1)\n",
        "print(new_noun_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGrNjxDMfgtz",
        "outputId": "fe5e823a-7d32-4961-9c32-05f5a4baf0f9"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the better to hug you with, my dear.\n",
            "All the make to hugged you with, my hello.\n",
            "All the getting to goodbye you with, my hello.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('All the better to hug you with, my dear.'):\n",
        "    if token.pos_=='ADJ':\n",
        "        print(token.text, token._.inflect('JJS'))\n",
        "        print(token.text, token._.inflect('JJR'))\n",
        "        print(token.text, token._.inflect('JJ'))\n",
        "        print(token.text, token._.inflect('NNS'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr8KF46-HOSZ",
        "outputId": "318d7b2c-77e7-4d92-a2a2-da49649f2f19"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "better best\n",
            "better better\n",
            "better well\n",
            "better wells\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('legs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rihm6tVHHObQ",
        "outputId": "1e7109b9-d370-48bb-8ff2-acb6c0df03b9"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('knees', 0.7576848864555359),\n",
              " ('neck', 0.7544339299201965),\n",
              " ('limbs', 0.7435048818588257),\n",
              " ('torso', 0.718532145023346),\n",
              " ('leg', 0.7134101986885071),\n",
              " ('abdomen', 0.7132607102394104),\n",
              " ('fingers', 0.7129844427108765),\n",
              " ('necks', 0.7127721309661865),\n",
              " ('toes', 0.7070165276527405),\n",
              " ('ankles', 0.7006694674491882)]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('All the better to run with, my child.'):\n",
        "    if token.pos_=='VERB':\n",
        "        print(token.text, token._.inflect('VB'))\n",
        "        print(token.text, token._.inflect('VBZ'))\n",
        "        print(token.text, token._.inflect('VBD'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0cMNKTGJgfX",
        "outputId": "c78563e1-6acc-4771-b3bf-7fb224ffab9d"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run run\n",
            "run runs\n",
            "run ran\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCu7WZuTJgp0",
        "outputId": "eaa49ef0-496e-4011-db30-51cac393a40d"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('running', 0.8024195432662964),\n",
              " ('runs', 0.7739369869232178),\n",
              " ('ran', 0.7490553259849548),\n",
              " ('out', 0.7392130494117737),\n",
              " ('go', 0.728611171245575),\n",
              " ('third', 0.7266499400138855),\n",
              " ('allowed', 0.7226610779762268),\n",
              " ('first', 0.7184870839118958),\n",
              " ('second', 0.7178599834442139),\n",
              " ('start', 0.7167410850524902)]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('ears')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V_KQ2O0JhFT",
        "outputId": "706988f6-1d3a-40f0-ff84-21ea69873df9"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ear', 0.8169093728065491),\n",
              " ('eyes', 0.7445225715637207),\n",
              " ('noses', 0.7245702743530273),\n",
              " ('lips', 0.7063229084014893),\n",
              " ('fingers', 0.7009091377258301),\n",
              " ('mouths', 0.6857833862304688),\n",
              " ('nose', 0.6725651621818542),\n",
              " ('legs', 0.664069652557373),\n",
              " ('tongue', 0.634791910648346),\n",
              " ('tongues', 0.6197501420974731)]"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# на случайные близкие слова и анти-слова\n",
        "noun = \"All the better to hug you with, my dear.\"\n",
        "new_noun_1, new_noun_2 = noun, noun\n",
        "i=5\n",
        "for token in nlp(noun):\n",
        "    if token.pos_ in ['NOUN', 'VERB', 'ADV', 'ADJ']:\n",
        "        m, n = np.random.randint(0, i, 2)\n",
        "\n",
        "        new_word_1 = model.most_similar(token.text.lower(), topn=i)[m][0]\n",
        "        new_word_2 = model.most_similar(positive = [token.text.lower(), 'bad'],\n",
        "                                        negative = ['good'],\n",
        "                                        topn=i)[n][0]\n",
        "\n",
        "        new_word_1 = new_word_1.title() if token.text.istitle() else new_word_1\n",
        "        new_word_2 = new_word_2.title() if token.text.istitle() else new_word_2\n",
        "\n",
        "        new_noun_1 = new_noun_1.replace(token.text, new_word_1)\n",
        "        new_noun_2 = new_noun_2.replace(token.text, new_word_2)\n",
        "\n",
        "print(noun)\n",
        "print(new_noun_1)\n",
        "print(new_noun_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sTFLzXfew9I",
        "outputId": "f9feaa3b-d05d-44cc-eeac-d49403bb181f"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the better to hug you with, my dear.\n",
            "All the get to kiss you with, my hello.\n",
            "All the even to kiss you with, my daddy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('child')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnGpa4Y9JhOT",
        "outputId": "0315d702-f585-487a-ec67-d0f5337c6b2b"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('children', 0.8553194999694824),\n",
              " ('mother', 0.7771131992340088),\n",
              " ('parents', 0.7735786437988281),\n",
              " ('girl', 0.7634811997413635),\n",
              " ('woman', 0.7601762413978577),\n",
              " ('boy', 0.7529667019844055),\n",
              " ('sex', 0.7461725473403931),\n",
              " ('pregnant', 0.7461138963699341),\n",
              " ('infant', 0.7323657870292664),\n",
              " ('daughter', 0.7290228605270386)]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# на случайные близкие слова и анти-слова\n",
        "noun = \"Grandmother, what big eyes you have!\"\n",
        "new_noun_1, new_noun_2 = noun, noun\n",
        "i=5\n",
        "for token in nlp(noun):\n",
        "    if token.pos_ in ['NOUN', 'VERB', 'ADV', 'ADJ']:\n",
        "        m, n = np.random.randint(0, i, 2)\n",
        "\n",
        "        new_word_1 = model.most_similar(token.text.lower(), topn=i)[m][0]\n",
        "        new_word_2 = model.most_similar(positive = [token.text.lower(), 'bad'],\n",
        "                                        negative = ['good'],\n",
        "                                        topn=i)[n][0]\n",
        "\n",
        "        new_word_1 = new_word_1.title() if token.text.istitle() else new_word_1\n",
        "        new_word_2 = new_word_2.title() if token.text.istitle() else new_word_2\n",
        "\n",
        "        new_noun_1 = new_noun_1.replace(token.text, new_word_1)\n",
        "        new_noun_2 = new_noun_2.replace(token.text, new_word_2)\n",
        "\n",
        "print(noun)\n",
        "print(new_noun_1)\n",
        "print(new_noun_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGuSYgJ2eRlW",
        "outputId": "f9389fb8-ad98-43be-8d38-915cbd0ba2fb"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grandmother, what big eyes you have!\n",
            "Grandmother, what huge smile you been!\n",
            "Grandmother, what huge lips you they!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in nlp('Grandmother, what big eyes you have!'):\n",
        "    if token.pos_=='VERB':\n",
        "        print(token.text, token._.inflect('VB'))\n",
        "        print(token.text, token._.inflect('VBZ'))\n",
        "        print(token.text, token._.inflect('VBD'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb6qpmyqK84O",
        "outputId": "a85ab7af-2a54-4262-9b17-35ce375269d7"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have have\n",
            "have has\n",
            "have had\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('with')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8RBbYatK9CB",
        "outputId": "db33aac4-abee-4476-9053-05de8038b883"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('over', 0.8443337082862854),\n",
              " ('both', 0.8336119055747986),\n",
              " ('and', 0.8332647681236267),\n",
              " ('two', 0.8263282775878906),\n",
              " ('well', 0.8233078122138977),\n",
              " ('while', 0.8223927021026611),\n",
              " ('by', 0.8067958354949951),\n",
              " ('as', 0.8017653226852417),\n",
              " ('.', 0.7975766062736511),\n",
              " ('one', 0.7949095368385315)]"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('teeth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fwwa9MWHOid",
        "outputId": "233b4a94-3923-459f-9c64-a76067cfc538"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bones', 0.7548375725746155),\n",
              " ('tooth', 0.7203940749168396),\n",
              " ('claws', 0.7042812705039978),\n",
              " ('jaw', 0.6967788934707642),\n",
              " ('jaws', 0.6908931136131287),\n",
              " ('legs', 0.6576513648033142),\n",
              " ('bone', 0.6443898677825928),\n",
              " ('tongue', 0.6401115655899048),\n",
              " ('skull', 0.6396577954292297),\n",
              " ('skin', 0.6392791271209717)]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# на случайные близкие слова и анти-слова\n",
        "noun = \"All the better to eat you up with.\"\n",
        "new_noun_1, new_noun_2 = noun, noun\n",
        "i=5\n",
        "for token in nlp(noun):\n",
        "    if token.pos_ in ['NOUN', 'VERB', 'ADV', 'ADJ']:\n",
        "        m, n = np.random.randint(0, i, 2)\n",
        "\n",
        "        new_word_1 = model.most_similar(token.text.lower(), topn=i)[m][0]\n",
        "        new_word_2 = model.most_similar(positive = [token.text.lower(), 'bad'],\n",
        "                                        negative = ['good'],\n",
        "                                        topn=i)[n][0]\n",
        "\n",
        "        new_word_1 = new_word_1.title() if token.text.istitle() else new_word_1\n",
        "        new_word_2 = new_word_2.title() if token.text.istitle() else new_word_2\n",
        "\n",
        "        new_noun_1 = new_noun_1.replace(token.text, new_word_1)\n",
        "        new_noun_2 = new_noun_2.replace(token.text, new_word_2)\n",
        "\n",
        "print(noun)\n",
        "print(new_noun_1)\n",
        "print(new_noun_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8nUo5JVMPpA",
        "outputId": "bf4c678c-be57-449b-b743-4cac33b35933"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the better to eat you up with.\n",
            "All the make to eaten you up with.\n",
            "All the even to consume you up with.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('wicked')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpKJbQ4gMPwo",
        "outputId": "2246777a-07ac-47c4-e796-fc3b40c36637"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('evil', 0.6611456274986267),\n",
              " ('mischievous', 0.6498479247093201),\n",
              " ('cruel', 0.6207956075668335),\n",
              " ('wacky', 0.5978850722312927),\n",
              " ('crazy', 0.5977882146835327),\n",
              " ('silly', 0.5966265797615051),\n",
              " ('sneaky', 0.5902952551841736),\n",
              " ('vicious', 0.5887827277183533),\n",
              " ('dumb', 0.5886535048484802),\n",
              " ('clever', 0.5797110795974731)]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('attractive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0mKw53wNaNr",
        "outputId": "74229bf2-61cd-4184-93fd-d3ccadd7d2aa"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('desirable', 0.730512261390686),\n",
              " ('unattractive', 0.6811944246292114),\n",
              " ('alluring', 0.6517535448074341),\n",
              " ('appealing', 0.6353302001953125),\n",
              " ('relatively', 0.6313267946243286),\n",
              " ('cheaper', 0.6293203830718994),\n",
              " ('very', 0.6291751861572266),\n",
              " ('priced', 0.6290417909622192),\n",
              " ('suitable', 0.6281996965408325),\n",
              " ('expensive', 0.6248573660850525)]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('dinner')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNbG2jfYNaYR",
        "outputId": "565a6f9b-7d3e-4006-d0f7-ab2bf0af330f"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('breakfast', 0.8415963053703308),\n",
              " ('dinners', 0.8142550587654114),\n",
              " ('lunch', 0.8033258318901062),\n",
              " ('luncheon', 0.7748416662216187),\n",
              " ('guests', 0.7565879821777344),\n",
              " ('banquet', 0.7558953166007996),\n",
              " ('brunch', 0.7384738326072693),\n",
              " ('meal', 0.714841902256012),\n",
              " ('meals', 0.6837010979652405),\n",
              " ('buffet', 0.682805597782135)]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('various')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3pk8IU4O4Y5",
        "outputId": "105941a1-70a0-40cc-d67c-ad5135c6de98"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('numerous', 0.8572206497192383),\n",
              " ('several', 0.8507537841796875),\n",
              " ('other', 0.8382675647735596),\n",
              " ('variety', 0.8348256349563599),\n",
              " ('different', 0.8308271765708923),\n",
              " ('these', 0.8201767206192017),\n",
              " ('such', 0.8062143325805664),\n",
              " ('include', 0.7874671220779419),\n",
              " ('many', 0.7858366966247559),\n",
              " ('including', 0.7760022282600403)]"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('charming')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLmpshMTO4hz",
        "outputId": "8ad8d82c-ca31-4259-c99c-dd30a812d688"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lovely', 0.805105447769165),\n",
              " ('beautiful', 0.7719314098358154),\n",
              " ('delightful', 0.7702623009681702),\n",
              " ('gorgeous', 0.7595885396003723),\n",
              " ('quirky', 0.7593000531196594),\n",
              " ('handsome', 0.7494663000106812),\n",
              " ('seductive', 0.740882158279419),\n",
              " ('amusing', 0.7366154193878174),\n",
              " ('likable', 0.7323250770568848),\n",
              " ('elegant', 0.7291433811187744)]"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('streets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhi8GICuPzcm",
        "outputId": "831fe4ad-434b-4c4b-d464-1f13190aff00"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('street', 0.7399185299873352),\n",
              " ('downtown', 0.7268213033676147),\n",
              " ('sidewalks', 0.7258997559547424),\n",
              " ('crowded', 0.71346116065979),\n",
              " ('neighborhoods', 0.6979953050613403),\n",
              " ('across', 0.6944648027420044),\n",
              " ('lined', 0.6841650605201721),\n",
              " ('crowds', 0.6825905442237854),\n",
              " ('roads', 0.6752520799636841),\n",
              " ('outside', 0.668502151966095)]"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сходные слова, синонимы\n",
        "model.similar_by_word('gentle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0me54-VPzo7",
        "outputId": "cc59331a-78c8-4eed-fad7-32b9816061a0"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('playful', 0.6820974946022034),\n",
              " ('charming', 0.64178866147995),\n",
              " ('lovely', 0.6381846070289612),\n",
              " ('breezy', 0.6363114714622498),\n",
              " ('cool', 0.6339117884635925),\n",
              " ('pleasant', 0.6335440874099731),\n",
              " ('quiet', 0.6328959465026855),\n",
              " ('easygoing', 0.6242066025733948),\n",
              " ('thoughtful', 0.623829185962677),\n",
              " ('wry', 0.6205047965049744)]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    }
  ]
}